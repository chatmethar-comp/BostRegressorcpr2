{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BostonRegressioncpr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhkys1UNV0eLO5he2ntpue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chatmethar-comp/BostRegressorcpr2/blob/main/BostonRegressioncpr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6041YXvkFwH"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFCKCgkYlTGQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "b7785a6d-a85e-4c53-b7c7-f0a745f71d29"
      },
      "source": [
        "boston = load_boston()\n",
        "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "y = pd.DataFrame(boston.target)\n",
        "X.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jutqG8y_vsDN",
        "outputId": "4ba68648-e1ee-47e2-bdca-43d334ac2fcf"
      },
      "source": [
        "X_train, X_test, y_train, y_test= train_test_split(X,y)\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(379, 13) (127, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co1EMjVaV-zP"
      },
      "source": [
        "## **gradient boosted tree regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhDJdPvR0D1F",
        "outputId": "e94fc02a-6abc-4953-ac97-34398710e1e4"
      },
      "source": [
        "regressor = GradientBoostingRegressor(\n",
        "    max_depth=2,\n",
        "    n_estimators=3,\n",
        "    learning_rate=1.0,\n",
        ")\n",
        "regressor.fit(X_train,y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=1.0, loss='ls', max_depth=2,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=3,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDTCeFCg2YH_",
        "outputId": "d8f5fc62-8afd-4a19-87d6-f0a29f174a50"
      },
      "source": [
        "errors = [mean_squared_error(y_test, y_pred) for y_pred in \n",
        "          regressor.staged_predict(X_test)]\n",
        "best_n_estimators = np.argmin(errors)\n",
        "print(errors)\n",
        "print(best_n_estimators)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25.28281823512201, 22.708816066824244, 18.71859949658222]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BymbWAWL8CUF",
        "outputId": "42831990-63e6-40aa-8d25-163a9e632d65"
      },
      "source": [
        "best_regressor = GradientBoostingRegressor(\n",
        "    max_depth = 2,\n",
        "    n_estimators = best_n_estimators,\n",
        "    learning_rate = 1.0\n",
        ")\n",
        "best_regressor.fit(X_train,y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=1.0, loss='ls', max_depth=2,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=2,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi5HNuiH8wgJ",
        "outputId": "4ed108c1-7837-4bd7-8f2d-5b8029e06311"
      },
      "source": [
        "y_pred = best_regressor.predict(X_test)\n",
        "mean_absolute_error(y_test,y_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5723630985834727"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ecXamzZCeTl",
        "outputId": "4b7977b5-f7f8-442a-a016-658eea5282a4"
      },
      "source": [
        "myregressor = GradientBoostingRegressor(\n",
        "    max_depth = 4,\n",
        "    n_estimators = 1200,\n",
        "    learning_rate = 0.1\n",
        ")\n",
        "myregressor.fit(X_train,y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='ls', max_depth=4,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=1200,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sma9X-m1Cu5p",
        "outputId": "859a9682-d265-46e1-f07c-9d4093ba001b"
      },
      "source": [
        "myy_pred = myregressor.predict(X_test)\n",
        "myerrors = [mean_squared_error(y_test,stagey_pred) for stagey_pred in myregressor.staged_predict(X_test)]\n",
        "print(myerrors)\n",
        "mean_absolute_error(y_test,myy_pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[73.16050245116298, 61.22634156198021, 51.697684790676, 43.82611276824337, 37.063962617056596, 31.93145671569711, 28.39451848093752, 25.05344531475586, 22.435264533504046, 20.09321539236557, 18.32027956134811, 16.71996418582027, 15.40318415401511, 14.333101630679428, 13.349789744274034, 12.577477577007878, 11.93572820796536, 11.517369511117755, 11.000249144366105, 10.665598600948583, 10.270307217048273, 10.0502502291813, 9.83470639363128, 9.665016878304552, 9.572077645935913, 9.496135006726757, 9.336554046978812, 9.092631095106242, 8.87627172616588, 8.82357858959851, 8.76609162926226, 8.695041395991318, 8.542854348435652, 8.495483398052423, 8.349431001278543, 8.281302650383278, 8.214949068920895, 8.190982383230216, 8.134672313173633, 8.086310966033784, 8.07214090563934, 8.063014002020685, 8.008083962937965, 7.966754327818205, 7.967227832512497, 7.946276363842343, 7.936542628766958, 7.926828812158013, 7.887651197594911, 7.9236425527622485, 7.920268313610108, 7.821620696525056, 7.816664267303612, 7.818751340782586, 7.794684472278374, 7.829141202083874, 7.783707139616728, 7.779249808777683, 7.7669981785827495, 7.74881867072669, 7.7477591558303285, 7.754162879492537, 7.749288900285704, 7.744619007190263, 7.724862651889987, 7.6973409425805, 7.651876299835039, 7.630855282468347, 7.644132045392542, 7.647072474728471, 7.653537783701959, 7.658492214738081, 7.6583305105887955, 7.65612563348098, 7.658334169854121, 7.657468066233286, 7.647913044832541, 7.648909372975609, 7.6519360039645665, 7.6335406217489945, 7.630187962557116, 7.622704017287017, 7.626554535189215, 7.630378671374262, 7.625569417921827, 7.600771407478049, 7.588496319653628, 7.537736375620721, 7.537894965840313, 7.505971985716754, 7.504173656193456, 7.510376072564728, 7.5079318587379, 7.4898264535869234, 7.460836872322138, 7.431912710514305, 7.435516302554996, 7.436606458670107, 7.438657092409504, 7.44020079331792, 7.439669417514081, 7.428919521129469, 7.421633011125502, 7.383049083699436, 7.391209781849594, 7.38332520914507, 7.389210859027465, 7.3934232047514294, 7.39054249520972, 7.352235014860881, 7.3426698776787696, 7.3425806373673, 7.339163259913771, 7.332184630727133, 7.327396777458191, 7.326285288439989, 7.320481809683434, 7.32539097278682, 7.299650802099444, 7.307836192686994, 7.3169519843075035, 7.314545416068627, 7.3082377216332155, 7.299484091750069, 7.294033718287049, 7.298852768785123, 7.297935046958781, 7.2983474821413425, 7.310946001495599, 7.314699710118518, 7.3117574122298885, 7.3365506332968815, 7.331267166293809, 7.333827357954615, 7.337564763548871, 7.303895081813632, 7.277234687502922, 7.2843605772811735, 7.28579839218105, 7.273077956688198, 7.28720875848273, 7.290109675962869, 7.2895383481708675, 7.2742344553772975, 7.283767239938979, 7.298436554606215, 7.300377026935178, 7.3106960608509, 7.31321434222006, 7.312286764050877, 7.306263366224107, 7.295984974461315, 7.2962752821472225, 7.295608599205833, 7.294703215413146, 7.298489528869182, 7.303504166325401, 7.295095667105417, 7.296313425132534, 7.309250120214064, 7.310425759691985, 7.299898545044627, 7.293883167252734, 7.311213543243827, 7.3166898322359835, 7.3175101900781065, 7.3039390068533905, 7.3011549147604855, 7.292191641461101, 7.286464012501964, 7.290333180867496, 7.289144761439451, 7.277796636540763, 7.290129131924466, 7.289831818604697, 7.273869543786509, 7.274195452595089, 7.270335210903913, 7.261168003562192, 7.2634723778975605, 7.267547606131831, 7.2606361260668875, 7.258459576027833, 7.257897706396044, 7.249101553528673, 7.245695785580139, 7.245626311040235, 7.24795475115001, 7.241992779511836, 7.239958634827132, 7.238389938780376, 7.236907004817017, 7.232987707352378, 7.237332537947712, 7.240088444318306, 7.250509734073221, 7.250430523741638, 7.247496736128709, 7.260181989233302, 7.2601729477618555, 7.2620935946783725, 7.263016793159185, 7.269697689098008, 7.262331692833646, 7.258128217859066, 7.259773439078436, 7.254550507912171, 7.2459577989323245, 7.244232333933918, 7.239266719991083, 7.2405691715598, 7.244062868738025, 7.2346753880461, 7.237594382547021, 7.2443336612143305, 7.250139275426308, 7.259756566825675, 7.254812428643024, 7.254503997936383, 7.253873209448184, 7.253245964642943, 7.254873318532834, 7.249741338791785, 7.256230058098622, 7.249744650900726, 7.249700804443434, 7.253503475950855, 7.248550128938975, 7.250696954664516, 7.250102789781566, 7.251882966640441, 7.257406045735245, 7.2575333756224385, 7.253256173200286, 7.253667421663879, 7.247296914822571, 7.258929553568766, 7.257881924274754, 7.255989871958258, 7.2600512366567465, 7.261850946568432, 7.2529053430960255, 7.251145066369398, 7.252594368947801, 7.241766272574082, 7.236832122752167, 7.2412884289784305, 7.245584443156906, 7.244849922245883, 7.246168680621756, 7.244760246509055, 7.242812884678986, 7.244680261553501, 7.246979747538917, 7.244363446918042, 7.248733882271565, 7.246438080827857, 7.241961458017152, 7.244691156454847, 7.238479218476931, 7.239898465011024, 7.244308993486493, 7.247709311755678, 7.248495667546186, 7.2483618894505515, 7.252493428528418, 7.250479278178245, 7.241515820656277, 7.241491620877446, 7.240573661868674, 7.235061297016308, 7.233452204854825, 7.23865978445016, 7.240779665212752, 7.240597916911713, 7.239015784805059, 7.239868064066346, 7.239061567437964, 7.238850620622175, 7.232988061739126, 7.230241039662488, 7.230426083352147, 7.2272836486803715, 7.224888035915306, 7.221456919672578, 7.217651691885857, 7.217188088042039, 7.215820327502221, 7.216831282736643, 7.2171579408482245, 7.218852083823176, 7.215465005901132, 7.21295232475317, 7.214265072844698, 7.214018564292183, 7.219067890427848, 7.213954122813893, 7.212875655993022, 7.21288028945241, 7.210551576526561, 7.208080875847872, 7.205528984681479, 7.205173045767614, 7.204240205075281, 7.206094966946842, 7.2057782400076755, 7.197245130224509, 7.196367422822581, 7.19472398901951, 7.193894401926041, 7.1935217879663504, 7.193486881201667, 7.193709031356109, 7.194093149264328, 7.190508963368338, 7.188611356320184, 7.18928794064943, 7.182629431697169, 7.1812540228074475, 7.178341336575493, 7.1792517845282715, 7.179520299313704, 7.181181316134608, 7.179724676177867, 7.179968012928917, 7.180796774854665, 7.181660682806532, 7.18265346582047, 7.183214159591878, 7.181691229782711, 7.1820789884543865, 7.178353559878143, 7.181108076937411, 7.180993809315314, 7.183985071914505, 7.187079354276436, 7.1877932138564455, 7.189377393604362, 7.188554134615613, 7.189837321221259, 7.193987945887574, 7.196337730529295, 7.1957618102969185, 7.197582095327847, 7.198267721572857, 7.199362279932066, 7.201564119360814, 7.200892026323982, 7.199544588992517, 7.200858235486262, 7.201410728641021, 7.205102901946242, 7.203563260805628, 7.203651009297442, 7.203637497259856, 7.201823361970168, 7.200160760914917, 7.198201221940206, 7.200708555105006, 7.201509292684246, 7.199608688187843, 7.197429656110436, 7.197211054617386, 7.197843071039321, 7.198351678956506, 7.1995874760000005, 7.20091249055006, 7.201830136560799, 7.197835443278877, 7.198078229090865, 7.1978912469177585, 7.195420576302783, 7.196230182299264, 7.1950989739368305, 7.192311683055785, 7.192582237901665, 7.192563841703675, 7.191506663429001, 7.192923292895958, 7.1951031945209225, 7.196381300955456, 7.19664119336452, 7.201172267427825, 7.200796237936455, 7.198103768392491, 7.198799469482506, 7.197484655406567, 7.195998217789935, 7.195531239232486, 7.195643693525744, 7.195873342387854, 7.196181626172914, 7.195407324674075, 7.1957911533682815, 7.1937676927497645, 7.192775339481716, 7.193697804958478, 7.192813441191838, 7.194214365551785, 7.194494662135545, 7.193341606969462, 7.192445104077758, 7.192192231135067, 7.193228571693762, 7.191143550881412, 7.187963905932523, 7.187206325855682, 7.187557559818162, 7.187004549483049, 7.1862879558280115, 7.185210492913205, 7.182875537617323, 7.180154110436847, 7.179789534566071, 7.179513674354248, 7.180165049312358, 7.1789339912286, 7.179582115597116, 7.1808778255756405, 7.180176750002639, 7.177727497061634, 7.178272297210225, 7.174399609310003, 7.172707962032469, 7.169482485093302, 7.172965857613242, 7.172682464245176, 7.170411574752919, 7.170325911089416, 7.167210958094793, 7.163707996229305, 7.160848808346649, 7.161135204614186, 7.160880324635124, 7.16123914241918, 7.159113366446242, 7.1569080223600565, 7.157106127382772, 7.1560269007562525, 7.155868615451062, 7.15522960155303, 7.15518012422647, 7.155012088251949, 7.154304864129539, 7.154700730709956, 7.155659043429424, 7.154470590219367, 7.154649296884447, 7.154332995922328, 7.153837343290307, 7.153844830441201, 7.151783441589787, 7.1522452812179, 7.1521016964547846, 7.152035678076217, 7.151316111023219, 7.15117463392434, 7.151230377877278, 7.152447809855522, 7.151607231625586, 7.148173007607015, 7.148561019652965, 7.147490694519499, 7.14683092031822, 7.148241833576639, 7.147996817835352, 7.149070483832558, 7.1491697294410885, 7.1494274325086025, 7.14824722912976, 7.147804290212789, 7.1486710395512585, 7.148948599489701, 7.148383449318671, 7.148685354352957, 7.148401219969361, 7.148930278238865, 7.148938037635776, 7.149766517755541, 7.150108615266821, 7.150909695303836, 7.151741249823207, 7.151459372743651, 7.151491572497313, 7.152857266711502, 7.153703873904934, 7.151156285422811, 7.149744991592252, 7.150545769253477, 7.150647365682688, 7.150103690607908, 7.150862352395257, 7.150924369868624, 7.150471024624874, 7.150716298856302, 7.150369688196626, 7.150505994020752, 7.150397892780015, 7.150281963339185, 7.148671855141958, 7.148286174850661, 7.148299703707108, 7.147801376697134, 7.148704780206164, 7.149053446876239, 7.150047550127657, 7.150772175787297, 7.1513230632470375, 7.151144662780964, 7.151646298682658, 7.151661609672626, 7.151989221779278, 7.1518759959412135, 7.151930316329777, 7.151840905783138, 7.152324749058853, 7.1531166586123405, 7.151014603049424, 7.150507949901921, 7.150694928626089, 7.150239561717137, 7.149473822504441, 7.149152196414863, 7.149085658193722, 7.148335749146926, 7.148280199642889, 7.146858650850269, 7.146780865192949, 7.146243095521223, 7.147254737491768, 7.147226101865299, 7.1478087458147685, 7.147257921478787, 7.147043520702685, 7.147120243744081, 7.147504436931989, 7.147146877167853, 7.146970234868597, 7.146138686185394, 7.146201807763844, 7.146485602488704, 7.146459163402622, 7.146456781363071, 7.146445512742229, 7.146911760447652, 7.1464368402585885, 7.146303444471235, 7.1464928890195045, 7.146888078730572, 7.146792781071657, 7.146230544137233, 7.145728428457224, 7.145775014773151, 7.145230605148759, 7.14464806210473, 7.145321904395169, 7.145216744601796, 7.145088956734066, 7.145099696143949, 7.145092033897946, 7.14470176671199, 7.144603395654211, 7.14450574159374, 7.14397717465183, 7.143813662013949, 7.1415956169304025, 7.1417864885557485, 7.1424831861849, 7.142051699521641, 7.1420963622426905, 7.142252984859189, 7.142305098128397, 7.142619494769878, 7.1420109933059885, 7.141898976246488, 7.141847571305616, 7.141639877979933, 7.141738419068012, 7.141658207834253, 7.141950439340326, 7.141649780383447, 7.1414309991238145, 7.142451558456645, 7.142702638361908, 7.1423000622130886, 7.142625954681048, 7.142601248761151, 7.142701431452618, 7.141633205805049, 7.14175791164519, 7.142139684315198, 7.141690444191043, 7.141485402313104, 7.141403160468288, 7.140831317005122, 7.140821056162361, 7.140574954952668, 7.1406515349554605, 7.141074553621809, 7.141463140317212, 7.142262459973202, 7.142345562763096, 7.142233403036838, 7.142142805676072, 7.141193653166712, 7.14102319610231, 7.141436272930985, 7.140604440538395, 7.140534506051401, 7.140303737396426, 7.140140190704209, 7.140089268489046, 7.1398555532136685, 7.1399560783615525, 7.140304333687749, 7.14038826817023, 7.140641685785028, 7.140666844101486, 7.141385218360783, 7.141455337437394, 7.141469051115877, 7.142029686828223, 7.141691736486021, 7.141580685221267, 7.141292589924767, 7.140591062397685, 7.140443857199093, 7.14041849425295, 7.140315039028379, 7.140553764104193, 7.140928641256248, 7.141020435263281, 7.141136462891252, 7.141049370016935, 7.141362605226826, 7.141358014933935, 7.140566594442553, 7.140905583003666, 7.140605001453966, 7.140828516052221, 7.140949244554998, 7.1402082305191, 7.140005849067488, 7.140145785754531, 7.140859536879906, 7.140137583893167, 7.140111693555554, 7.140109055941547, 7.140374382952605, 7.140789852021874, 7.140651368957819, 7.141832028985421, 7.141851726402594, 7.141859873582235, 7.141915023534032, 7.1415504252585675, 7.1413127193799495, 7.141169577856597, 7.140669201187879, 7.14064983578815, 7.140381394169698, 7.140250245960383, 7.14044405507831, 7.140368037363978, 7.140261710188432, 7.140320391016114, 7.140294321640193, 7.140243316805149, 7.139907774436178, 7.140064310114559, 7.139879134832568, 7.140041746853867, 7.140009502787878, 7.139749277197074, 7.140184509010617, 7.1403736914841955, 7.140274776615312, 7.1403208383802985, 7.140472454167612, 7.1405064391112845, 7.1405946393582225, 7.140402804891542, 7.140369181526019, 7.1400959890690014, 7.140115314092929, 7.1404523741287225, 7.14047762284191, 7.140640157728751, 7.140857574040706, 7.140933948878363, 7.140987202958592, 7.14086686195117, 7.140866510420862, 7.140985444456789, 7.140621340547442, 7.141144786404985, 7.1411841935781055, 7.141261764777284, 7.1410370034467565, 7.1409945613593395, 7.141130685495436, 7.141195103692983, 7.141271618663159, 7.141216410521026, 7.141359723436077, 7.1411108722239485, 7.141252183930961, 7.141275772737316, 7.141282869598039, 7.141293618539493, 7.14109841827721, 7.14109065579505, 7.14084996492689, 7.140838097619916, 7.14080798920655, 7.140824680943663, 7.140841385414561, 7.140833470364946, 7.140911763420622, 7.140999873814403, 7.140941831189051, 7.140945520143162, 7.140888057194911, 7.140921117778168, 7.140983993215712, 7.14072783199725, 7.140503410776426, 7.140464920506983, 7.140859070158365, 7.140951531205664, 7.140844773493644, 7.14106089892842, 7.1410418185862, 7.141129905631315, 7.141051350017366, 7.141067925395563, 7.140949040259519, 7.140819216136576, 7.140743671874322, 7.140755324428521, 7.140725679612376, 7.140674088535973, 7.140635990943953, 7.140756701169232, 7.140755097044986, 7.140575890649804, 7.140562740912829, 7.140555057623388, 7.140573113024917, 7.140439388308834, 7.1405297095339115, 7.140469444890065, 7.140650218424698, 7.14054632412084, 7.140480794023005, 7.140372903786717, 7.140494844496727, 7.140454329690751, 7.14016187732774, 7.14006948552548, 7.14007049301272, 7.140147024087563, 7.140180877725419, 7.1400907018613395, 7.140141592985709, 7.14029140074904, 7.1402532401111465, 7.139759274289423, 7.139854962663162, 7.139815652636722, 7.139885102945173, 7.139769161018639, 7.139835378079494, 7.139853413639467, 7.139802995787213, 7.139786219496068, 7.139773262737878, 7.139834383302827, 7.1397579892772445, 7.139890582964096, 7.140006630193214, 7.139986338825542, 7.139966393976248, 7.13980985643715, 7.139854576645522, 7.1398086335613575, 7.139840691130241, 7.139941680067663, 7.139892679028009, 7.1398641573685175, 7.139781210151991, 7.139786360822901, 7.13990361243685, 7.139855392801088, 7.139857249262595, 7.1398657119205655, 7.1396788843037005, 7.1396189917206145, 7.139619544800611, 7.1395089135070675, 7.1394325226158015, 7.1393576964318655, 7.139145318063618, 7.139081390440258, 7.13907977315545, 7.139074195292373, 7.1391433887698605, 7.1391307023870425, 7.139199584726574, 7.139242983783337, 7.139286599429251, 7.139331707524291, 7.139341750104058, 7.139254871423909, 7.139209350306971, 7.139251019206323, 7.139178127433706, 7.139047091922023, 7.139072745371488, 7.139032894982077, 7.138949246171785, 7.138787157414231, 7.138933424017769, 7.138956211560995, 7.138935273450545, 7.138961576125403, 7.138941157831509, 7.138970242384312, 7.138810915658823, 7.138781012625848, 7.1386540454297345, 7.13849199775754, 7.138412544064478, 7.138421950117189, 7.138440708567427, 7.138338902584291, 7.138577227282166, 7.138568067864465, 7.1385460283721525, 7.138428027900883, 7.13843335454101, 7.138490589026925, 7.138318359039245, 7.138368902846876, 7.138325417749742, 7.138364743770404, 7.138282187574095, 7.138374325676818, 7.138301914065276, 7.138164904759561, 7.138166026351976, 7.138163573736972, 7.138002901356319, 7.138007134084826, 7.138013698803702, 7.138039824218963, 7.138082730697918, 7.138014679502868, 7.137933066093547, 7.1379205880663505, 7.137925461500781, 7.137983614259331, 7.137931410133487, 7.137988237964857, 7.137998935703409, 7.137870479869715, 7.137933117219941, 7.137912406552052, 7.138018891354986, 7.138019971538793, 7.1380712168068605, 7.138019096905071, 7.13804287797189, 7.138127937064236, 7.138090521713773, 7.138117433683061, 7.138182863118765, 7.138098044979201, 7.138081634031471, 7.138096040317893, 7.138076804460737, 7.138082905521461, 7.138089966320645, 7.138091175965687, 7.138049648631759, 7.138133279118855, 7.138050279854105, 7.138010478904314, 7.137975383144449, 7.138007657860106, 7.138087783401093, 7.1380733914224885, 7.138120169699762, 7.138116681648629, 7.138085593318243, 7.138180013241718, 7.138144129822164, 7.1380920775432966, 7.138126163853657, 7.138127363663596, 7.138096855483935, 7.138236026729409, 7.138087805534176, 7.138108640864354, 7.138108436516859, 7.138118401182665, 7.138125454903146, 7.138165950041711, 7.138124607251585, 7.138101085977701, 7.138150358760446, 7.138075347876209, 7.138081700194243, 7.138014939962911, 7.138048579645709, 7.138102683166699, 7.138096969871339, 7.1381315808034085, 7.138101969656262, 7.137968208017717, 7.137949357127244, 7.137844604068286, 7.137814003289349, 7.137780826330088, 7.137787233955788, 7.137861410085242, 7.1377797240193965, 7.137761214972703, 7.13775570239736, 7.137775737145702, 7.137722108998223, 7.137707543345939, 7.1377293359621525, 7.1376700267356386, 7.13765911020108, 7.137651813869486, 7.137702195339934, 7.137715464378065, 7.137609825067218, 7.1375775405513915, 7.137506862132113, 7.137318729611275, 7.137307293111432, 7.137263370364519, 7.137302801273711, 7.137308500100704, 7.137219849713116, 7.137182181530507, 7.137198816041879, 7.137188913839527, 7.137182731352419, 7.137152302890308, 7.137129712019283, 7.137140744730473, 7.1371356620289985, 7.1371485655725895, 7.137131295038928, 7.137103329195231, 7.137039216076649, 7.137054155778206, 7.136982633441301, 7.13699211213897, 7.137021996923868, 7.136996767814622, 7.137003975964836, 7.137012515036776, 7.1370299404490956, 7.137004779962605, 7.137025893300519, 7.1368803673682795, 7.136898199760957, 7.136918594415678, 7.136931984522154, 7.136927611027184, 7.136945113877579, 7.136930197127373, 7.1369284082762485, 7.136928317770438, 7.136947604633684, 7.136932172412936, 7.13694000805453, 7.136960624800949, 7.136940449413048, 7.136943531400764, 7.136935940165713, 7.136925542178053, 7.136921514187172, 7.13693498685642, 7.136919729719485, 7.136779202428907, 7.1367375832853615, 7.136726665101658, 7.136711360595521, 7.136636616422549, 7.136615449097354, 7.136632955733258, 7.136630120948875, 7.136648064727114, 7.136638098497395, 7.136639062502645, 7.136494495408042, 7.136487364480375, 7.136474094988054, 7.136453597537183, 7.136441528046133, 7.136435236450366, 7.136439954077878, 7.1364588620373155, 7.13644574357268, 7.13645189521588, 7.136451508394023, 7.136468198932675, 7.13646641830727, 7.136468041221593, 7.136488368442309, 7.1365071690685085, 7.136449710123723, 7.136447365970072, 7.136445615165046, 7.136438497946952, 7.136449199226744, 7.136453633730023, 7.136416820046702, 7.136401230122904, 7.136420065718149, 7.136426557604373, 7.136458929944904, 7.1364575680193285, 7.1364688484032905, 7.136475884354822, 7.136494908307457, 7.1365157317716665, 7.136538149229411, 7.136576006570336, 7.136632623914697, 7.136635934925773, 7.136631728436703, 7.136632230064566, 7.136666638592686, 7.136653423499783, 7.136652838874167, 7.136652480541673, 7.136638123959211, 7.136626121378845, 7.136625587188604, 7.136633526044521, 7.136633661241304, 7.136613515040313, 7.1366286026949535, 7.136635322681026, 7.1366287928022505, 7.136654117254194, 7.136625456747436, 7.136622035698557, 7.136603843417334, 7.136607566039609, 7.136605278444944, 7.1366075763187995, 7.136609357043439, 7.136591931125964, 7.136596422806436, 7.13658608452774, 7.136583883926612, 7.136581599958757, 7.136579137733377, 7.136593054041218, 7.136627323887974, 7.136619920146539, 7.136626802141019, 7.136625945361466, 7.136634701904374, 7.136606613464727, 7.136604133823562, 7.1366015319706255, 7.136601027597301, 7.136603554285997, 7.136599864859041, 7.136602394482691, 7.136599129628635, 7.136610692508661, 7.136600931872619, 7.136583376288561, 7.136585386673731, 7.136579365065531, 7.136571646628556, 7.136574676223914, 7.136573495149866, 7.136606021539577, 7.136612543629979, 7.1366182817765145, 7.136609616209242, 7.136591360001508, 7.136577014882065, 7.136565683765466, 7.136595118585069, 7.136621372208631, 7.1366008848692015, 7.136616554883627, 7.136630806211101, 7.136630196859596, 7.1366033324795275, 7.136598546206477, 7.136608490481432, 7.136605482678399, 7.136615590822589, 7.136619967952831, 7.13662958113473, 7.136611728508353, 7.13661717307689, 7.136653922221493, 7.136659004414762, 7.136669622367593, 7.136675129068877, 7.136681909929806, 7.136695859391153, 7.136691817736567, 7.136687550746053, 7.136698562233131, 7.136676584703768, 7.136669593702857, 7.136645613561123, 7.136639472226955, 7.136642341749214, 7.136635659242582, 7.13663020666249, 7.136640208148137, 7.136634992078087, 7.136645023034384, 7.136654879392283, 7.136658404684641, 7.13668126158811, 7.13668815047214, 7.136691168254133, 7.136683979850075, 7.136677453371845, 7.1366729550117, 7.136670088994099, 7.136602165597824, 7.136616998235205, 7.136635503317862, 7.136618287473052, 7.136640291270658, 7.136662716736903, 7.136659624568075, 7.13667128695176, 7.1366693228075615, 7.136666340842658, 7.13666179987443, 7.136654255357964, 7.136650613995535, 7.1366530691768455, 7.136655287395628, 7.136651846255581, 7.136659229991812, 7.1366626590914235, 7.136655271305334, 7.1366763421968225, 7.136669641466951, 7.136674012847321, 7.136659129243173, 7.136659031912663, 7.13666938007318, 7.136659489530968, 7.136657268522629, 7.136649296906611, 7.136651271492126, 7.136663829773889, 7.136629572153621, 7.13662356246619, 7.1366258345509275, 7.136617812491883, 7.136615517516397, 7.136609906062092, 7.136599767208927, 7.1365638589700895, 7.136552929934276, 7.136550383942595, 7.136542572660483, 7.136540048999357, 7.136549819513013, 7.136554741226518, 7.136550697894283, 7.136556595962707, 7.136555140812312, 7.136556522560038, 7.13656179082552, 7.136565387604899, 7.136549163237211, 7.136551713450678, 7.136543685516146, 7.136545943753374, 7.136561710361537, 7.136559874471879, 7.136551566879128, 7.136571488127704, 7.1365846107200985, 7.136607537402381, 7.136601905383449, 7.136609649905028, 7.136603445431923]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9639818052169296"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06C0-c7_qkJC",
        "outputId": "638f493a-5be1-4fec-a666-0f5891e0ef38"
      },
      "source": [
        "h = [5,1,4,72,2]\n",
        "np.argmin(h)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_9KG2IGFdvk"
      },
      "source": [
        "## **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuh01msvq8L1",
        "outputId": "ebd2d4f8-c8a1-4e4d-d3aa-1957ea0b482d"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dt_regressor = DecisionTreeRegressor(max_depth = 3)\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "dt_pred = dt_regressor.predict(X_test)\n",
        "mean_absolute_error(dt_pred,y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.165334948504548"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC8UriZsC-lM"
      },
      "source": [
        "## **supported vector regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOC59iZaCfbs"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuBgXZfsDKUV",
        "outputId": "802d2d78-a020-4cc5-9d29-789b563586f9"
      },
      "source": [
        "sc_X = StandardScaler()\n",
        "sc_Y = StandardScaler()\n",
        "standardized_X = sc_X.fit_transform(X)\n",
        "standardized_Y = sc_Y.fit_transform(y)\n",
        "print(standardized_X)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.41978194  0.28482986 -1.2879095  ... -1.45900038  0.44105193\n",
            "  -1.0755623 ]\n",
            " [-0.41733926 -0.48772236 -0.59338101 ... -0.30309415  0.44105193\n",
            "  -0.49243937]\n",
            " [-0.41734159 -0.48772236 -0.59338101 ... -0.30309415  0.39642699\n",
            "  -1.2087274 ]\n",
            " ...\n",
            " [-0.41344658 -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
            "  -0.98304761]\n",
            " [-0.40776407 -0.48772236  0.11573841 ...  1.17646583  0.4032249\n",
            "  -0.86530163]\n",
            " [-0.41500016 -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
            "  -0.66905833]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcG9YOxCDwqO",
        "outputId": "2858d80c-6b79-4092-e3ca-dabbf0fd2384"
      },
      "source": [
        "SVR_regressor = SVR(kernel= 'rbf')\n",
        "SVR_regressor.fit(standardized_X,standardized_Y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhsy3wpLEIvL",
        "outputId": "a7680b57-9cec-4054-a808-24031e1b86a8"
      },
      "source": [
        "standardized_X_test = sc_X.fit_transform(X_test)\n",
        "standardized_y_test = sc_Y.fit_transform(y_test)\n",
        "SVR_y_pred = SVR_regressor.predict(X_test)\n",
        "mean_absolute_error(SVR_y_pred,standardized_y_test)\n",
        "np.sqrt(mean_squared_error(SVR_y_pred,standardized_y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0019947830193259"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}